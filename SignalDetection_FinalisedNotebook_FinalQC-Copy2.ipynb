{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e13a031d",
   "metadata": {},
   "source": [
    "# Notebook for analysing data to find potential signals within\n",
    "# \n",
    "\n",
    "### How does this script work?\n",
    "First saved data in .txt form is loaded in and the dataset is extracted. The dataset is then ran through a pipeline looking for potential signals within the data and finally Dataframes are created with the characteristics of the full dataset and any signals within\n",
    "# \n",
    "### How does the pipeline work?\n",
    "The data is first analysed my a machine learning model. This model is un-supervised and is looking for regions in the data where there is high volatility, indicating a potential region of interest where a signal may be.\n",
    "\n",
    "The predictions made by the model are then looked at and any regions of interest are saved and looked into with more detail. This invloves using a cross correlation function to determine if the signal has the characteristic curve, if the extracted signal is extremely long then the cross correlation function is used to see if there is a signal within the region of interest. If the cross correlation functions show a signal is present then they are analysed looking at the length, number of peaks and height of the peaks as well as the depth of the dip. If the cross correlation function shows no signal is present then the region of interest is discarded."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8f1071d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import MLDetectionFunctionsPythonV9_5_NoRestricts_MLcreate as EEGanalysis\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import ipywidgets as widgets\n",
    "from ipywidgets import interact, interactive, Output, fixed, interact_manual\n",
    "from IPython.display import display, clear_output\n",
    "import numpy as np\n",
    "import math\n",
    "import mat73\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "119a0101",
   "metadata": {},
   "outputs": [],
   "source": [
    "#jupyter serverextension enable --py jupyter_resource_usage --sys-prefix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aefe025b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#I think need to add some length to end of extraction so can be cropped down\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#AMAZING IDEA\n",
    "\n",
    "#What if I saved all individual areas of interest extracted by the model\n",
    "#this includes seizure events and non-seizure events\n",
    "#use this to train a model that can classify each extracted area of interest\n",
    "\n",
    "#save both raw and smoothed AoI and see which has better results\n",
    "\n",
    "\n",
    "\n",
    "#Try first - just key infor in dataframe to train with\n",
    "\n",
    "#using the extracted dataframe at the end of the code use this with either 'Signal' or 'Noise'\n",
    "#to train a model which can then be used to classify extracted AoI instead of full signals\n",
    "\n",
    "#trim down dataframe so doesnt include confusing info eg start and end times\n",
    "#intead just have signal length\n",
    "\n",
    "#include cross-corr score as well in dataframe\n",
    "#think of other things to input into the dataframe\n",
    "\n",
    "#maybe use rounded signal length (in seconds) as well as rounded dip depth, medium peak height\n",
    "\n",
    "#look at peak density throughout signal\n",
    "#rolling average over 10secs and pick median, mean or peak value?\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#this looks to be a very good idea\n",
    "\n",
    "\n",
    "#TO CHANGE\n",
    "#If subsignal found i.e. 12.1, 12.2 (from 12.0) then need to delete the 12.0 signal"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1566f48",
   "metadata": {},
   "source": [
    "# Importing data to analyse\n",
    "\n",
    "### Each dataset should be saved as a .txt file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3608c6d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "realdatafile1 = 'Long_Data_1.txt'\n",
    "realdatafile2 = 'Long_Data_2.txt'\n",
    "realdatafile3 = 'Long_Data_3.txt'\n",
    "realdatafile4 = 'Long_Data_4.txt'\n",
    "\n",
    "realdatafile5 = 'Short_Data_1.txt'\n",
    "\n",
    "realdatafile6 = '22.07.22_Example_Data_Long.txt'\n",
    "realdatafile7 = '22.07.22_Example_Data_Long2.txt'\n",
    "\n",
    "realdatafile8 = '041022_Example_Data_Long_NoisyMW117CH1.txt'\n",
    "realdatafile9 = '041022_Example_Data_Long_SpikesMW117CH3.txt'\n",
    "\n",
    "realdatafile10 = '12.10.22_Example_Data_Long_Spikes-Venus16.3CH1.txt' #this is same as a previous file\n",
    "\n",
    "realdatafile11 = '041022ExampleDataLongVenus13p1CH1.txt' #could be all noise as 'signals' all very short\n",
    "realdatafile12 = '041022ExampleDataLongVenus13p1CH2.txt' #also very difficult to classify as nearly all could be signal or noise\n",
    "realdatafile13 = '041122ExampleDataLongVenus7p3CH3.txt'\n",
    "realdatafile14 = '041122ExampleDataLongVenus7p3CH4.txt'\n",
    "realdatafile15 = '041122ExampleDataLongVenus10p1CH1.txt'\n",
    "realdatafile16 = '041122ExampleDataLongVenus10p1CH2.txt'\n",
    "realdatafile17 = '041122ExampleDataLongVenus12p3CH1.txt'\n",
    "realdatafile18 = '041122ExampleDataLongVenus12p3CH2.txt'\n",
    "realdatafile19 = '041122ExampleDataLongVenus13p3CH1.txt' #no extractions\n",
    "realdatafile20 = '041122ExampleDataLongVenus13p3CH2.txt' #no extractions\n",
    "\n",
    "#start of novel analysis\n",
    "realdatafile21 = '21.11./mnt/datafast/Douglas/MaxTransfer/Data040523/01.03.22 - MW109 - CH1 - 0 Mg.txt23 - MW3 - CH2.txt'\n",
    "realdatafile22 = '21.12.02 - MW30 - CH3.txt'\n",
    "realdatafile23 = '22.01.24 - MW63 - CH2.txt' #unique error\n",
    "realdatafile24 = '22.01.24 - MW65 - CH1.txt'\n",
    "realdatafile25 = '22.01.21 - MW61 - CH2.txt'\n",
    "realdatafile26 = '21.12.14 - MW51 - CH2.txt'\n",
    "realdatafile27 = '21.12.15 - MW58 - CH3.txt' #lots of very smooth signals, well detected and classified\n",
    "\n",
    "\n",
    "noveldata1 = '/mnt/datafast/Douglas/MaxTransfer/NewDataToAnalyse/21.11.23 - MW3 - CH2.txt' #some signals, extractions possibly too long\n",
    "noveldata2 = '/mnt/datafast/Douglas/MaxTransfer/NewDataToAnalyse/21.11.23 - MW5 - CH2.txt' #unique error FIXED. 2 extractions, both seem to be calibration noise classified as signal\n",
    "noveldata3 = '/mnt/datafast/Douglas/MaxTransfer/NewDataToAnalyse/21.11.25 - MW7 - CH1.txt' #single extraction, noise\n",
    "noveldata4 = '/mnt/datafast/Douglas/MaxTransfer/NewDataToAnalyse/21.11.25 - MW9 - CH2.txt' #same unique error FIXED. about 10 extractions, all noise except a few calibrations classified as signal\n",
    "noveldata5 = '/mnt/datafast/Douglas/MaxTransfer/NewDataToAnalyse/21.11.29 - MW13 - CH3.txt' #one extraction, noise\n",
    "noveldata6 = '/mnt/datafast/Douglas/MaxTransfer/NewDataToAnalyse/21.11.30 - MW19 - CH2.txt' #3 extracts, all noise\n",
    "noveldata7 = '/mnt/datafast/Douglas/MaxTransfer/NewDataToAnalyse/21.11.30 - MW19 - CH4.txt' #no extracts\n",
    "noveldata8 = '/mnt/datafast/Douglas/MaxTransfer/NewDataToAnalyse/21.12.02 - MW21 - CH4.txt' #3 extracts, all noise\n",
    "noveldata9 = '/mnt/datafast/Douglas/MaxTransfer/NewDataToAnalyse/21.12.02 - MW25 - CH1.txt' #4 signals extracted, last one possible starting too early\n",
    "noveldata10 = '/mnt/datafast/Douglas/MaxTransfer/NewDataToAnalyse/21.12.02 - MW29 - CH1.txt' #4 extracts, 1/2 disputable signals\n",
    "noveldata11 = '/mnt/datafast/Douglas/MaxTransfer/NewDataToAnalyse/21.12.02 - MW29 - CH2.txt' #4 extracts, all noise\n",
    "noveldata12 = '/mnt/datafast/Douglas/MaxTransfer/NewDataToAnalyse/21.12.02 - MW30 - CH3.txt' #1 extract, noise\n",
    "noveldata13 = '/mnt/datafast/Douglas/MaxTransfer/NewDataToAnalyse/21.12.02 - MW32 - CH4.txt' #no extractions\n",
    "noveldata14 = '/mnt/datafast/Douglas/MaxTransfer/NewDataToAnalyse/21.12.06 - MW33 - CH2.txt' #4 extracts. all noise but 1 wrongly classified as signal\n",
    "noveldata15 = '/mnt/datafast/Douglas/MaxTransfer/NewDataToAnalyse/21.12.06 - MW35 - CH1.txt' #4 extracts, all noise\n",
    "noveldata16 = '/mnt/datafast/Douglas/MaxTransfer/NewDataToAnalyse/21.12.06 - MW36 - CH4.txt' #1 extract, noise\n",
    "noveldata17 = '/mnt/datafast/Douglas/MaxTransfer/NewDataToAnalyse/21.12.08 - MW41 - CH1.txt' #v strong signals. 4 extracts, 3 clear signals, 1 possible noise/signal\n",
    "noveldata18 = '/mnt/datafast/Douglas/MaxTransfer/NewDataToAnalyse/21.12.08 - MW42 - CH3.txt' #again, some good signals. 7 extractions, some signal and noise. all well classified\n",
    "noveldata19 = '/mnt/datafast/Douglas/MaxTransfer/NewDataToAnalyse/21.12.09 - MW46 - CH4.txt' #dubios signal extractions. look to be a rig calibration\n",
    "noveldata20 = '/mnt/datafast/Douglas/MaxTransfer/NewDataToAnalyse/21.12.14 - MW51 - CH2.txt' #8 extracts, mainly noise with 1 possible signal\n",
    "noveldata21 = '/mnt/datafast/Douglas/MaxTransfer/NewDataToAnalyse/21.12.14 - MW53 - CH1.txt'#mega dataset size. lots of extractions 30+, many signals and noise\n",
    "noveldata22 = '/mnt/datafast/Douglas/MaxTransfer/NewDataToAnalyse/21.12.14 - MW54 - CH3.txt'#mega dataset size, 40+ extractions. lots of signals and noise\n",
    "noveldata23 = '/mnt/datafast/Douglas/MaxTransfer/NewDataToAnalyse/21.12.15 - MW58 - CH3.txt'#nice example dataset. lots of very well extracted signals\n",
    "noveldata24 = '/mnt/datafast/Douglas/MaxTransfer/NewDataToAnalyse/21.12.15 - MW58 - CH4.txt'#struggles with correct detection (could make for good training data). lots of single dips classified as signal\n",
    "noveldata25 = '/mnt/datafast/Douglas/MaxTransfer/NewDataToAnalyse/22.01.21 - MW61 - CH2.txt'#lots of extractions, many noise and some signals. signals are of interesting shape\n",
    "noveldata26 = '/mnt/datafast/Douglas/MaxTransfer/NewDataToAnalyse/22.01.24 - MW63 - CH1.txt'#generally good extraction, maybe cuts some signals short\n",
    "noveldata27 = '/mnt/datafast/Douglas/MaxTransfer/NewDataToAnalyse/22.01.24 - MW63 - CH2.txt'#a few nice signals but also some noise (possibly some misclassified noise)\n",
    "noveldata28 = '/mnt/datafast/Douglas/MaxTransfer/NewDataToAnalyse/22.01.24 - MW64 - CH3.txt' # lots of signals and noise, some possibly misclassified\n",
    "noveldata29 = '/mnt/datafast/Douglas/MaxTransfer/NewDataToAnalyse/22.01.24 - MW65 - CH1.txt'#only 2 extractions, both nosie\n",
    "noveldata30 = '/mnt/datafast/Douglas/MaxTransfer/NewDataToAnalyse/22.01.24 - MW65 - CH2.txt' #7 extractions, all noise but 2 possible signals\n",
    "#re-run all novel data as MainDataframe wasnt sorted correctly and could have incorrect predictions for the signal number\n",
    "#signals that were X.1 X.2 might not be sorted correctly\n",
    "\n",
    "\n",
    "realdatafile21van = '2022_09_30_socialtaskephys_exp_SGHRB_subject2777_Int16ch5K0_I2C625Hz_1ADC200K_IR320K.edf'\n",
    "realdatafile22van = '2022_09_30_socialtaskephys_exp_SGHRB_subject2777_Int16ch5K0_I2C625Hz_1ADC200K_IR320K.mat'\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "curvedata = 'SpikeWaveDischarge.txt'\n",
    "\n",
    "#add start and end vals to compare with Max spreadsheet into dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76f89ac8",
   "metadata": {},
   "outputs": [],
   "source": [
    "datamay1 = '/mnt/datafast/Douglas/MaxTransfer/Data040523/01.03.22 - MW109 - CH1 - 0 Mg.txt' #two very similar signals\n",
    "datamay2 = '/mnt/datafast/Douglas/MaxTransfer/Data040523/01.03.22 - MW109 - CH2 - 0 Mg.txt' #two very similar signals\n",
    "datamay3 = '/mnt/datafast/Douglas/MaxTransfer/Data040523/01.03.22 - MW110 - CH3 - 0 Mg.txt' #some confusing signals\n",
    "datamay4 = '/mnt/datafast/Douglas/MaxTransfer/Data040523/01.03.22 - MW110 - CH4 - 0 Mg.txt' #two signals, some dubious noise\n",
    "datamay5 = '/mnt/datafast/Douglas/MaxTransfer/Data040523/02.02.22 - MW71 - CH2 - 4-AP.txt' #lots of extractions, some signals possibly cropped too early finish. lots of noise/signal mixups possible\n",
    "datamay6 = '/mnt/datafast/Douglas/MaxTransfer/Data040523/03.02.22 - MW73 - CH1 - 4-AP.txt' #some good signals, some noise/signal dubious\n",
    "datamay7 = '/mnt/datafast/Douglas/MaxTransfer/Data040523/03.02.22 - MW73 - CH2 - 4-AP.txt' #a few too long extractions\n",
    "datamay8 = '/mnt/datafast/Douglas/MaxTransfer/Data040523/03.02.22 - MW74 - CH3 - 4-AP.txt' #a few too long extractions\n",
    "datamay9 = '/mnt/datafast/Douglas/MaxTransfer/Data040523/03.02.22 - MW74 - CH4 - 4-AP.txt' #fairly good\n",
    "datamay10 = '/mnt/datafast/Douglas/MaxTransfer/Data040523/03.02.22 - MW75 - CH1 - 4-AP.txt' #Very good example\n",
    "\n",
    "datamay11 = '/mnt/datafast/Douglas/MaxTransfer/Data040523/03.02.22 - MW75 - CH2 - 4-AP.txt' #good extractions, nice example\n",
    "datamay12 = '/mnt/datafast/Douglas/MaxTransfer/Data040523/03.02.22 - MW76 - CH3 - 4-AP.txt' #lots of signals, unique look to them\n",
    "datamay13 = '/mnt/datafast/Douglas/MaxTransfer/Data040523/03.02.22 - MW76 - CH4 - 4-AP.txt' #lots od extracts, some boarderline singla/noise and plenty singal\n",
    "datamay14 = '/mnt/datafast/Douglas/MaxTransfer/Data040523/03.02.22 - MW77 - CH2 - 0 Mg.txt' #only 3 signals but good extracts\n",
    "datamay15 = '/mnt/datafast/Douglas/MaxTransfer/Data040523/07.02.22 - MW79 - CH1 - 4-AP.txt' #nice clean extractions, 1 maybe too early\n",
    "datamay16 = '/mnt/datafast/Douglas/MaxTransfer/Data040523/07.02.22 - MW79 - CH2 - 4-AP.txt' #lots of clean extractions, maybe 2 too early\n",
    "datamay17 = '/mnt/datafast/Douglas/MaxTransfer/Data040523/07.02.22 - MW80 - CH3 - 0 MG.txt' #only noise\n",
    "datamay18 = '/mnt/datafast/Douglas/MaxTransfer/Data040523/07.02.22 - MW80 - CH4 - 0 MG.txt' #only noise\n",
    "datamay19 = '/mnt/datafast/Douglas/MaxTransfer/Data040523/08.02.22 - MW81 - CH1 - 4-AP.txt' #very smooth signals\n",
    "datamay20 = '/mnt/datafast/Douglas/MaxTransfer/Data040523/08.02.22 - MW81 - CH2 - 4-AP.txt' #lots of signals, really cool dataset\n",
    "\n",
    "datamay21 = '/mnt/datafast/Douglas/MaxTransfer/Data040523/08.02.22 - MW83 - CH1 - 0 Mg.txt' #all noise except one very dubious signal\n",
    "datamay22 = '/mnt/datafast/Douglas/MaxTransfer/Data040523/08.02.22 - MW83 - CH2 - 0 Mg.txt' #only 2 signals, but very similar so quite cool\n",
    "datamay23 = '/mnt/datafast/Douglas/MaxTransfer/Data040523/14.03.22 - MW115 - CH1 - 0 Mg.txt' #1 very dubious thing\n",
    "datamay24 = '/mnt/datafast/Douglas/MaxTransfer/Data040523/14.03.22 - MW115 - CH2 - 0 Mg.txt' #only noise\n",
    "datamay25 = '/mnt/datafast/Douglas/MaxTransfer/Data040523/14.03.22 - MW116 - CH3 - 0 Mg.txt' #very nice signals. some issues with centering on dip as subsequent global min\n",
    "datamay26 = '/mnt/datafast/Douglas/MaxTransfer/Data040523/14.03.22 - MW116 - CH4 - 0 Mg.txt' #really interesting super smooth signals\n",
    "datamay27 = '/mnt/datafast/Douglas/MaxTransfer/Data040523/15.03.22 - MW117 - CH1 - 4-AP.txt' #has double extracted signal\n",
    "datamay28 = '/mnt/datafast/Douglas/MaxTransfer/Data040523/15.03.22 - MW117 - CH2 - 4-AP.txt' #nice signals\n",
    "datamay29 = '/mnt/datafast/Douglas/MaxTransfer/Data040523/15.03.22 - MW118 - CH3 - 4-AP.txt' #just 2 signals\n",
    "datamay30 = '/mnt/datafast/Douglas/MaxTransfer/Data040523/15.03.22 - MW118 - CH4 - 4-AP.txt' #2 signals\n",
    "\n",
    "datamay31 = '/mnt/datafast/Douglas/MaxTransfer/Data040523/16.03.22 - MW123 - CH1 - 0 Mg.txt' #1 signal, some other dubious ones\n",
    "datamay32 = '/mnt/datafast/Douglas/MaxTransfer/Data040523/16.03.22 - MW123 - CH2 - 0 Mg.txt' #some nice signals, again global min is not the actual dip\n",
    "datamay33 = '/mnt/datafast/Douglas/MaxTransfer/Data040523/16.03.22 - MW123 - CH3 - 0 Mg.txt' #6 signals\n",
    "datamay34 = '/mnt/datafast/Douglas/MaxTransfer/Data040523/16.03.22 - MW123 - CH4 - 0 Mg.txt' #3 signals\n",
    "datamay35 = '/mnt/datafast/Douglas/MaxTransfer/Data040523/21.02.22 - MW85 - CH1 - 4-AP.txt' #9 fairly similar signals, nice dataset\n",
    "datamay36 = '/mnt/datafast/Douglas/MaxTransfer/Data040523/21.02.22 - MW87 - CH1 - 0 Mg.txt' #4 nice signals\n",
    "datamay37 = '/mnt/datafast/Douglas/MaxTransfer/Data040523/21.02.22 - MW87 - CH2 - 0 Mg.txt' #4 nice signals\n",
    "datamay38 = '/mnt/datafast/Douglas/MaxTransfer/Data040523/21.02.22 - MW89 - CH3 - 0 Mg.txt' #no clear signals\n",
    "datamay39 = '/mnt/datafast/Douglas/MaxTransfer/Data040523/21.02.22 - MW89 - CH4 - 0 Mg.txt' #2 long signals, lots of single spikes\n",
    "datamay40 = '/mnt/datafast/Douglas/MaxTransfer/Data040523/22.02.22 - MW91 - CH1 - 0 Mg.txt' #3 signals\n",
    "\n",
    "datamay41 = '/mnt/datafast/Douglas/MaxTransfer/Data040523/22.02.22 - MW91 - CH2 - 0 Mg.txt' #small individual dips\n",
    "datamay42 = '/mnt/datafast/Douglas/MaxTransfer/Data040523/22.02.22 - MW93 - CH1 - 0 Mg.txt' #9 good signals\n",
    "datamay43 = '/mnt/datafast/Douglas/MaxTransfer/Data040523/22.02.22 - MW93 - CH2 - 0 Mg.txt' #some signals and some HUGE aplitude stuff (noise?)\n",
    "datamay44 = '/mnt/datafast/Douglas/MaxTransfer/Data040523/24.02.22 - MW99 - CH1 - 4-AP.txt' #really good signals\n",
    "datamay45 = '/mnt/datafast/Douglas/MaxTransfer/Data040523/24.02.22 - MW99 - CH2 - 4-AP.txt' #good signals\n",
    "datamay46 = '/mnt/datafast/Douglas/MaxTransfer/Data040523/24.02.22 - MW101 - CH1 - 0 Mg.txt' #2 nice signals. no noise\n",
    "datamay47 = '/mnt/datafast/Douglas/MaxTransfer/Data040523/24.02.22 - MW101 - CH2 - 0 Mg.txt' #2 nice signals. no noise\n",
    "datamay48 = '/mnt/datafast/Douglas/MaxTransfer/Data040523/24.02.22 - MW102 - CH3 - 0 Mg.txt' #2 signals, some single noise dips\n",
    "datamay49 = '/mnt/datafast/Douglas/MaxTransfer/Data040523/24.02.22 - MW102 - CH4 - 0 Mg.txt' #single dips, possible signals\n",
    "datamay50 = '/mnt/datafast/Douglas/MaxTransfer/Data040523/25.02.22 - MW103 - CH1 - 0 Mg.txt' #lots of nice signals\n",
    "\n",
    "datamay51 = '/mnt/datafast/Douglas/MaxTransfer/Data040523/25.02.22 - MW103 - CH2 - 0 Mg.txt' #lots of nice signals\n",
    "datamay52 = '/mnt/datafast/Douglas/MaxTransfer/Data040523/25.02.22 - MW104 - CH3 - 0 Mg.txt' #2 signals\n",
    "datamay53 = '/mnt/datafast/Douglas/MaxTransfer/Data040523/25.02.22 - MW104 - CH4 - 0 Mg.txt' #2/3 signals\n",
    "datamay54 = '/mnt/datafast/Douglas/MaxTransfer/Data040523/28.02.22 - MW107 - CH1 - 0 Mg.txt' #10/11 really nice signals\n",
    "datamay55 = '/mnt/datafast/Douglas/MaxTransfer/Data040523/28.02.22 - MW107 - CH2 - 0 Mg.txt' #again, plenty really nice signals\n",
    "datamay56 = '/mnt/datafast/Douglas/MaxTransfer/Data040523/28.02.22 - MW108 - CH3 - 0 Mg.txt' #no noise, 4 clear signals with one being longer\n",
    "datamay57 = '/mnt/datafast/Douglas/MaxTransfer/Data040523/28.02.22 - MW108 - CH4 - 0 Mg.txt' #quite spikey signals, interesting\n",
    "datamay58 = '/mnt/datafast/Douglas/MaxTransfer/Data040523/31.03.22 - MW126 - CH1 - 4-AP.txt' #23 extracts, 5-10 signal the rest noise/single dips\n",
    "datamay59 = '/mnt/datafast/Douglas/MaxTransfer/Data040523/31.03.22 - MW126 - CH2 - 4-AP.txt' #a few signals but a lot of single spikes too"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e7a9dad",
   "metadata": {},
   "source": [
    "# Choosing which dataset to analyse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94f24dc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "datasetusing = datamay36\n",
    "\n",
    "#check 5, boarderline on signal/noise (especially 3rd signal)\n",
    "\n",
    "#8 is good for testing with 'clean' dataset that works v well with original 9_5 version\n",
    "\n",
    "#11 has detection issues\n",
    "#14 is cool as works well\n",
    "#15 cool too\n",
    "#16 is v good\n",
    "#17 detection issues due to dip depth too small and thus removing signal\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "660880c8",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42669d8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "realdatausing = EEGanalysis.getdata(datasetusing)\n",
    "realdatausing\n",
    "\n",
    "DFnorm, signal = EEGanalysis.CreateDataframe(realdatausing)\n",
    "DFnormres, signalres2 = EEGanalysis.CreateDataframe(realdatausing)\n",
    "\n",
    "\n",
    "\n",
    "# Formatting the curve data to use in cross correlation to determine validity of potential signals\n",
    "\n",
    "\n",
    "\n",
    "curvedata = EEGanalysis.getdata(curvedata)\n",
    "timecurve, signalcurve = EEGanalysis.timesignal(curvedata)\n",
    "signalcurveave = EEGanalysis.movingaverage(signalcurve[:,1],10000)\n",
    "\n",
    "\n",
    "\n",
    "# Predicting the locations of potential signals within the dataset\n",
    "\n",
    "\n",
    "\n",
    "StartVals, EndVals, signalCURVES = EEGanalysis.PredictSignal(DFnorm, signal,350000)\n",
    "\n",
    "\n",
    "\n",
    "# Analysing the whole dataset before and potential signals have been removed\n",
    "\n",
    "\n",
    "\n",
    "MainSignalDFtestfull = EEGanalysis.AnalyseSignalFullData(signal)\n",
    "\n",
    "\n",
    "\n",
    "# Extracting potential individual signals, determining their validity and analysing them where necessary\n",
    "\n",
    "\n",
    "\n",
    "MainSignalDF, MainSignalDFraw, MainSignalDFccextracts,redsig = EEGanalysis.AnalyseSignalsFailsafeVer(StartVals,EndVals,signal,signalres2,signalCURVES,DFnorm,signalcurveave,250000)\n",
    "\n",
    "\n",
    "\n",
    "# Analysing the remaining data after valid signals have been removed\n",
    "\n",
    "\n",
    "\n",
    "MainSignalDFtestfullthird = EEGanalysis.AnalyseSignalFullData(redsig)\n",
    "\n",
    "\n",
    "\n",
    "# Dataframe containing characteristics of full original data\n",
    "\n",
    "\n",
    "\n",
    "MainSignalDFtestfull\n",
    "\n",
    "\n",
    "\n",
    "# Dataframe containing characteristics of initially extracted signals, not including any second tier extractions\n",
    "\n",
    "\n",
    "\n",
    "MainSignalDFraw\n",
    "\n",
    "\n",
    "\n",
    "# Dataframe containing characteristics of only second tier extractions\n",
    "\n",
    "### This is where a signal was within an initial extraction but the original signal contained more data then just the signal\n",
    "\n",
    "### The signal is extracted using cross correlation to trim out the 'excess' data from the original extraction\n",
    "\n",
    "\n",
    "\n",
    "MainSignalDFccextracts\n",
    "\n",
    "\n",
    "\n",
    "# Dataframe containing the characteristics of the full data with signals removed\n",
    "\n",
    "\n",
    "\n",
    "MainSignalDFtestfullthird\n",
    "\n",
    "\n",
    "\n",
    "# Combining the dataframes containing original extracted signals and second tier extractions\n",
    "\n",
    "### Original extractions are labelled with .0 i.e. 5.0 or 8.0\n",
    "\n",
    "### Second tier extractions are labelled with .1 .2 .3 depending on how many second tier extractions there are within one original signal  i.e original signal 6 may have two signals within it and they would be labelled 6.1 and 6.2   original signal 9 may have one signal within it and would be labelled 9.1\n",
    "\n",
    "\n",
    "\n",
    "MainSignalDFtot = MainSignalDFraw.append(MainSignalDFccextracts, ignore_index=True)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "MainSignalDFtot['SignalNumber'] = MainSignalDFtot['SignalNumber'].str.split('Signal').str.join('')\n",
    "MainSignalDFtot['SignalNumber'] = pd.to_numeric(MainSignalDFtot['SignalNumber'])\n",
    "MainSignalDFtot=MainSignalDFtot.sort_values('SignalNumber')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "MainSignalDF = MainSignalDF.rename(columns={\"Startsig\": \"Start Time (s)\", \"Endsig\": \"End Time (s)\"\n",
    "                                           , \"SignalLength\": \"Signal Length (s)\"\n",
    "                                           , \"NoPeaksBeforeGlobal\": \"Peaks Before Global Min\"\n",
    "                                           , \"NoPeaksAfterGlobal\": \"Peaks After Global Min\"\n",
    "                                           , \"NoDipsBeforeGlobal\": \"Dips Before Global Min\"\n",
    "                                           , \"NoDipsAfterGlobal\": \"Dips After Global Min\"\n",
    "                                           , \"DipDepth\": \"Global Min Depth\"\n",
    "                                           , \"Start\": \"Start Index\"\n",
    "                                           , \"End\": \"End Index\"})\n",
    "\n",
    "\n",
    "\n",
    "realdataV2 = EEGanalysis.getdata(datasetusing)\n",
    "DFnorm3, signalres3 = EEGanalysis.CreateDataframe(realdataV2)\n",
    "\n",
    "\n",
    "\n",
    "MainSignalDF = MainSignalDF.fillna(0)\n",
    "\n",
    "\n",
    "\n",
    "MainSignalDF = MainSignalDF.sort_index()\n",
    "\n",
    "\n",
    "\n",
    "MainSignalDFpred = MainSignalDF.sort_index()\n",
    "MainSignalDFpred = MainSignalDFpred.astype(float).round(0).astype(int)\n",
    "\n",
    "\n",
    "\n",
    "MainSignalDFpred = MainSignalDFpred.drop('Start Time (s)', axis=1)\n",
    "MainSignalDFpred = MainSignalDFpred.drop('End Time (s)', axis=1)\n",
    "MainSignalDFpred = MainSignalDFpred.drop('Start Index', axis=1)\n",
    "MainSignalDFpred = MainSignalDFpred.drop('End Index', axis=1)\n",
    "MainSignalDFpred = MainSignalDFpred.drop('SignalNumber', axis=1)\n",
    "MainSignalDFpred\n",
    "\n",
    "\n",
    "\n",
    "MLclassifier = pickle.load(open('PotentialSignalClassifier.sav', 'rb'))\n",
    "\n",
    "\n",
    "\n",
    "MainSignalDFpredar = MainSignalDFpred.to_numpy()\n",
    "\n",
    "\n",
    "\n",
    "prediction = MLclassifier.predict(MainSignalDFpredar)\n",
    "\n",
    "#reduce number of outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49ea02aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('All Curves Overlaid:')\n",
    "for a in range(len(MainSignalDF)):\n",
    "    plt.plot(signalres3[MainSignalDF['Start Time (s)'][a]*5000:MainSignalDF['End Time (s)'][a]*5000,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb734838",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('All Curves Staggared:')\n",
    "for a in range(len(MainSignalDF)):\n",
    "    plt.plot(signalres3[MainSignalDF['Start Time (s)'][a]*5000:MainSignalDF['End Time (s)'][a]*5000,1]-2000*(a+1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c934289",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for a in range(len(MainSignalDF)):\n",
    "    print('Graph of Extracted Curve %s'%a)\n",
    "    print('Signal Length: %ss'%MainSignalDFpred['Signal Length (s)'][a])\n",
    "    print(prediction[a])\n",
    "    plt.plot(signalres3[MainSignalDF['Start Time (s)'][a]*5000:MainSignalDF['End Time (s)'][a]*5000,1])\n",
    "    plt.show()\n",
    "    print()\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac7e69b3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b9bbd3d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "682af08c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a542ad35",
   "metadata": {},
   "outputs": [],
   "source": [
    "for a in range(len(MainSignalDF)):\n",
    "    print('Graph of Extracted Curve %s'%a)\n",
    "    print('Signal Length: %ss'%MainSignalDFpred['Signal Length (s)'][a])\n",
    "    print('Prediction:%s' %prediction[a])\n",
    "    plt.plot(signalres3[MainSignalDF['Start Time (s)'][a]*5000:MainSignalDF['End Time (s)'][a]*5000,1])\n",
    "    plt.show()\n",
    "    \n",
    "    def f(Signal):\n",
    "            1+1\n",
    "\n",
    "    #locals()[\"my_result\"+str(a)] = interactive(f, Signal=True)\n",
    "    locals()[\"my_result\"+str(a)] = widgets.RadioButtons(options=['Signal', 'Noise'],description='Signal or Noise:',disabled=False)\n",
    "\n",
    "    display(locals()[\"my_result\"+str(a)])\n",
    "    \n",
    "    locals()[\"UnuseableWhy\"+str(a)] = input(\"If Signal Unuseable, Why? (Leave Blank and Press Enter if Useable)\")\n",
    "    \n",
    "    \n",
    "    \n",
    "    input(\"Press Enter to Confirm\")\n",
    "    \n",
    "\n",
    "    print()\n",
    "    print()\n",
    "    clear_output()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9add40f",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(MainSignalDF)):\n",
    "    print(locals()[\"my_result\"+str(i)].value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fd2e86c",
   "metadata": {},
   "outputs": [],
   "source": [
    "MainSignalDF['User Entry'] = np.nan\n",
    "MainSignalDF['Unuseable Reason'] = np.nan\n",
    "\n",
    "for i in range(len(MainSignalDF)):\n",
    "    MainSignalDF['User Entry'][i] = locals()[\"my_result\"+str(i)].value\n",
    "        \n",
    "for i in range(len(MainSignalDF)):\n",
    "        MainSignalDF['Unuseable Reason'][i] = locals()[\"UnuseableWhy\"+str(i)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6ef4f40",
   "metadata": {},
   "outputs": [],
   "source": [
    "MainSignalDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a21357ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "for a in range(len(MainSignalDF)):\n",
    "    if MainSignalDF['User Entry'][a] == 'Noise':\n",
    "        MainSignalDF = MainSignalDF.drop([a])\n",
    "        \n",
    "MainSignalDF = MainSignalDF.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef7306f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "MainSignalDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "585dd1db",
   "metadata": {},
   "outputs": [],
   "source": [
    "globals()[iter] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6cc8bdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "DropdownOptions = []\n",
    "for i in range(len(MainSignalDF)):\n",
    "    DropdownOptions.append(('Signal %s'%str(i+1), i))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "649e6503",
   "metadata": {},
   "source": [
    "# Run the following cell two times, and interact with it the on the second run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1fce623",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%matplotlib notebook\n",
    "from numpy import pi, sin\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.widgets import Slider, Button, RadioButtons\n",
    "\n",
    "\n",
    "SignalSelector = widgets.Dropdown(\n",
    "    options=DropdownOptions,\n",
    "    value=globals()[iter],\n",
    "    description='Signal:',\n",
    ")\n",
    "\n",
    "def reset_button_on_clicked(mouse_event):\n",
    "    start_slider.reset()\n",
    "    end_slider.reset()\n",
    "    \n",
    "def confirm_button_on_clicked(mouse_event):\n",
    "    ax.cla()\n",
    "    [line] = ax.plot(x, y, linewidth=0.5, color='black')\n",
    "    highlightplotstart = ax.axvline(((start_slider.val/200)*(np.max(x)-np.min(x))) + np.min(x), color='green', zorder=-1)\n",
    "    highlightplotend = ax.axvline(np.max(x) - ((end_slider.val/200)*(np.max(x)-np.min(x))), color='red', zorder=-1)\n",
    "    highlightzone = ax.axvspan(((start_slider.val/200)*(np.max(x)-np.min(x))) + np.min(x), np.max(x) - ((end_slider.val/200)*(np.max(x)-np.min(x))), color='green', alpha=0.25)\n",
    "    fig.canvas.draw_idle()\n",
    "    globals()[\"StartCrop\"+str(globals()[iter])] = start_slider.val\n",
    "    globals()[\"EndCrop\"+str(globals()[iter])] = end_slider.val\n",
    "    \n",
    "    \n",
    "def sliders_on_changedstart(val):\n",
    "    ax.cla()\n",
    "    [line] = ax.plot(x, y, linewidth=0.5, color='black')\n",
    "    highlightplotstart = ax.axvline(((start_slider.val/200)*(np.max(x)-np.min(x))) + np.min(x), color='green', zorder=-1)\n",
    "    highlightplotend = ax.axvline(np.max(x) - ((end_slider.val/200)*(np.max(x)-np.min(x))), color='red', zorder=-1)\n",
    "    fig.canvas.draw_idle()\n",
    "    \n",
    "def sliders_on_changedend(val):\n",
    "    ax.cla()\n",
    "    [line] = ax.plot(x, y, linewidth=0.5, color='black')\n",
    "    highlightplotstart = ax.axvline(((start_slider.val/200)*(np.max(x)-np.min(x))) + np.min(x), color='green', zorder=-1)\n",
    "    highlightplotend = ax.axvline(np.max(x) - ((end_slider.val/200)*(np.max(x)-np.min(x))), color='red', zorder=-1)\n",
    "    fig.canvas.draw_idle()\n",
    "    \n",
    "    \n",
    "x = signalres3[MainSignalDF['Start Time (s)'][globals()[iter]]*5000:MainSignalDF['End Time (s)'][globals()[iter]]*5000,0]\n",
    "\n",
    "y = signalres3[MainSignalDF['Start Time (s)'][globals()[iter]]*5000:MainSignalDF['End Time (s)'][globals()[iter]]*5000,1]\n",
    "    \n",
    "\n",
    "\n",
    "axis_color = 'lightgoldenrodyellow'\n",
    "\n",
    "fig = plt.figure(figsize=(10,5))\n",
    "ax = fig.add_subplot(111)\n",
    "\n",
    "fig.subplots_adjust(left=0.25, bottom=0.25)\n",
    "\n",
    "[line] = ax.plot(x, y, linewidth=0.5, color='black')\n",
    "\n",
    "\n",
    "\n",
    "start_slider_ax  = fig.add_axes([0.25, 0.15, 0.65, 0.03], facecolor=axis_color)\n",
    "start_slider = Slider(start_slider_ax, 'Start', 0, 100, valinit=0)\n",
    "\n",
    "end_slider_ax = fig.add_axes([0.25, 0.1, 0.65, 0.03], facecolor=axis_color)\n",
    "end_slider = Slider(end_slider_ax, 'End', 0, 100, valinit=0)\n",
    "\n",
    "#highlightplot = ax.axvspan(start_slider.val/2, 100 - end_slider.val/2, color='green', alpha=0.5)\n",
    "highlightplotstart = ax.axvline(np.min(x), color='green', zorder=-1)\n",
    "highlightplotend = ax.axvline(np.max(x), color='red', zorder=-1)\n",
    "    \n",
    "start_slider.on_changed(sliders_on_changedstart)\n",
    "end_slider.on_changed(sliders_on_changedend)\n",
    "\n",
    "reset_button_ax = fig.add_axes([0.8, 0.025, 0.1, 0.04])\n",
    "reset_button = Button(reset_button_ax, 'Reset', color='red', hovercolor='0.975')\n",
    "\n",
    "confirm_button_ax = fig.add_axes([0.25, 0.025, 0.1, 0.04])\n",
    "confirm_button = Button(confirm_button_ax, 'Confirm', color='green', hovercolor='0.975')\n",
    "    \n",
    "reset_button.on_clicked(reset_button_on_clicked)\n",
    "confirm_button.on_clicked(confirm_button_on_clicked)\n",
    "\n",
    "    \n",
    "plt.show()\n",
    "\n",
    "def on_change(change):\n",
    "    if change['type'] == 'change' and change['name'] == 'value':\n",
    "        print(\"changed to %s\" % change['new'])\n",
    "        globals()[iter] = change['new']\n",
    "        \n",
    "        %rerun\n",
    "       \n",
    "\n",
    "SignalSelector.observe(on_change)\n",
    "\n",
    "display(SignalSelector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0834e9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "SignalCropPercs = pd.DataFrame(columns = ['Signal', 'Start Perc', 'End Perc'])\n",
    "Signallist = []\n",
    "Startlist = []\n",
    "Endlist = []\n",
    "for i in range(len(MainSignalDF)):\n",
    "    Signallist.append('Signal %s'%str(i+1))\n",
    "    Startlist.append(globals()[\"StartCrop\"+str(i)])#SignalCropPercs['Start Perc'][i] = ['StartCrop%s'%i]\n",
    "    Endlist.append(globals()[\"EndCrop\"+str(i)])#SignalCropPercs['End Perc'][i] = ['EndCrop%s'%i]\n",
    "    \n",
    "SignalCropPercs['Signal'] = Signallist\n",
    "SignalCropPercs['Start Perc'] = Startlist\n",
    "SignalCropPercs['End Perc'] = Endlist\n",
    "\n",
    "SignalCropPercs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9286d3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "MainSignalDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5856ebb",
   "metadata": {},
   "outputs": [],
   "source": [
    "StartIndice = MainSignalDF['Start Time (s)']*5000\n",
    "EndIndice = MainSignalDF['End Time (s)']*5000\n",
    "SignalLengthIndice = EndIndice - StartIndice\n",
    "SignalMidpointIndice = SignalLengthIndice/2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88c62e6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "StartIndice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8eca85d",
   "metadata": {},
   "outputs": [],
   "source": [
    "EndIndice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e08b67fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "SignalLengthIndice/5000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75e88166",
   "metadata": {},
   "outputs": [],
   "source": [
    "SignalMidpointIndice/5000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8067d7b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "CropStartIndice = StartIndice + (SignalCropPercs['Start Perc']/100)*SignalMidpointIndice\n",
    "#100% = midpoint\n",
    "#0% = startpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76dd908b",
   "metadata": {},
   "outputs": [],
   "source": [
    "CropEndIndice = EndIndice - (SignalCropPercs['End Perc']/100)*SignalMidpointIndice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "095cd7e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "CropStartIndice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8d23535",
   "metadata": {},
   "outputs": [],
   "source": [
    "CropEndIndice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0157ac1",
   "metadata": {},
   "outputs": [],
   "source": [
    "CropSignalTEST = pd.DataFrame(columns = ['Start', 'End'])\n",
    "CropSignalTEST['Start'] = CropStartIndice/5000\n",
    "CropSignalTEST['End'] = CropEndIndice/5000\n",
    "CropSignalTEST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d7cfadc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "for a in range(len(CropSignalTEST)):\n",
    "    print('Graph of Extracted Curve %s'%a)\n",
    "    print('Signal Length: %ss'%(int(CropSignalTEST['End'][a])-int(CropSignalTEST['Start'][a])))\n",
    "    plt.rcParams['figure.figsize'] = [100, 50]\n",
    "    plt.plot(signalres3[int(CropSignalTEST['Start'][a]*5000):int(CropSignalTEST['End'][a]*5000),1])\n",
    "    plt.show()\n",
    "    print()\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d68a419b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "MainSignalDFTEST = EEGanalysis.AnalyseSignalsCROPPED(CropSignalTEST['Start']*5000,CropSignalTEST['End']*5000,signalres3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4ac088e",
   "metadata": {},
   "outputs": [],
   "source": [
    "MainSignalDFTEST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fb828f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('All Curves Overlaid:')\n",
    "for a in range(len(MainSignalDFTEST)):\n",
    "        \n",
    "    argmin = np.argmin(signalres3[MainSignalDFTEST['Startsig'][a]*5000:MainSignalDFTEST['Endsig'][a]*5000,1])\n",
    "    signalres3[MainSignalDFTEST['Startsig'][a]*5000:MainSignalDFTEST['Endsig'][a]*5000,0] = range(0,len(signalres3[MainSignalDFTEST['Startsig'][a]*5000:MainSignalDFTEST['Endsig'][a]*5000,0]))\n",
    "    signalres3[MainSignalDFTEST['Startsig'][a]*5000:MainSignalDFTEST['Endsig'][a]*5000,0] = signalres3[MainSignalDFTEST['Startsig'][a]*5000:MainSignalDFTEST['Endsig'][a]*5000,0] - argmin\n",
    "    \n",
    "    plt.plot(signalres3[MainSignalDFTEST['Startsig'][a]*5000:MainSignalDFTEST['Endsig'][a]*5000,0],signalres3[MainSignalDFTEST['Startsig'][a]*5000:MainSignalDFTEST['Endsig'][a]*5000,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7d5126c",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('All Curves Staggared:')\n",
    "count = 0\n",
    "offset = 4000\n",
    "for a in range(len(MainSignalDFTEST)):\n",
    "    \n",
    "    argmin = np.argmin(signalres3[MainSignalDFTEST['Startsig'][a]*5000:MainSignalDFTEST['Endsig'][a]*5000,1])\n",
    "    signalres3[MainSignalDFTEST['Startsig'][a]*5000:MainSignalDFTEST['Endsig'][a]*5000,0] = range(0,len(signalres3[MainSignalDFTEST['Startsig'][a]*5000:MainSignalDFTEST['Endsig'][a]*5000,0]))\n",
    "    signalres3[MainSignalDFTEST['Startsig'][a]*5000:MainSignalDFTEST['Endsig'][a]*5000,0] = signalres3[MainSignalDFTEST['Startsig'][a]*5000:MainSignalDFTEST['Endsig'][a]*5000,0] - argmin\n",
    "    \n",
    "    plt.plot(signalres3[MainSignalDFTEST['Startsig'][a]*5000:MainSignalDFTEST['Endsig'][a]*5000,0],signalres3[MainSignalDFTEST['Startsig'][a]*5000:MainSignalDFTEST['Endsig'][a]*5000,1]-offset*(count+1))\n",
    "    count = count+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bb5a494",
   "metadata": {},
   "outputs": [],
   "source": [
    "drugStart = [0,5000]\n",
    "drugEnd = [5000,7500]\n",
    "\n",
    "drugsNumber = input(\"Number of Drugs Used? \")\n",
    "drugName = list()\n",
    "drugColour = list()\n",
    "for i in range(int(drugsNumber)):\n",
    "    locals()[\"Drug\"+str(i)] = input(\"Name of Drug Number %s: \" %str(i+1))\n",
    "    locals()[\"DrugColour\"+str(i)] = input(\"Colour of Drug Number %s: \" %str(i+1))\n",
    "    drugName.append(locals()[\"Drug\"+str(i)])\n",
    "    drugColour.append(locals()[\"DrugColour\"+str(i)])\n",
    "    \n",
    "print(drugName) \n",
    "print(drugColour)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16ff50b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#go through each row of MainSignalDFTEST\n",
    "\n",
    "#if start time of signal is "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b4b1c06",
   "metadata": {},
   "outputs": [],
   "source": [
    "MainSignalDFTEST['Startsig'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d03b1c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "drugUsed = [None]*len(MainSignalDFTEST)\n",
    "for i in range(len(MainSignalDFTEST)):    \n",
    "    for x in range(len(drugStart)):\n",
    "        if MainSignalDFTEST['Startsig'][i] - drugEnd[x] < 0:\n",
    "            drugUsed[i] = drugName[x]\n",
    "            break\n",
    "            \n",
    "MainSignalDFTEST['Drug'] = drugUsed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c29be6cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "MainSignalDFTEST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfc71bad",
   "metadata": {},
   "outputs": [],
   "source": [
    "testtest = MainSignalDFTEST.loc[(MainSignalDFTEST['Drug'] == 'B')]\n",
    "testtest = testtest.reset_index()\n",
    "testtest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10016913",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for i in range(len(drugName)):\n",
    "\n",
    "    MainSignalDrugUsing = MainSignalDFTEST.loc[(MainSignalDFTEST['Drug'] == drugName[i])]\n",
    "    MainSignalDrugUsing = MainSignalDrugUsing.reset_index()\n",
    "    print('All %s Curves Overlaid:'%drugName[i])\n",
    "    for a in range(len(MainSignalDrugUsing)):\n",
    "        \n",
    "        argmin = np.argmin(signalres3[MainSignalDrugUsing['Startsig'][a]*5000:MainSignalDrugUsing['Endsig'][a]*5000,1])\n",
    "        signalres3[MainSignalDrugUsing['Startsig'][a]*5000:MainSignalDrugUsing['Endsig'][a]*5000,0] = range(0,len(signalres3[MainSignalDrugUsing['Startsig'][a]*5000:MainSignalDrugUsing['Endsig'][a]*5000,0]))\n",
    "        signalres3[MainSignalDrugUsing['Startsig'][a]*5000:MainSignalDrugUsing['Endsig'][a]*5000,0] = signalres3[MainSignalDrugUsing['Startsig'][a]*5000:MainSignalDrugUsing['Endsig'][a]*5000,0] - argmin\n",
    "    \n",
    "        plt.plot(signalres3[MainSignalDrugUsing['Startsig'][a]*5000:MainSignalDrugUsing['Endsig'][a]*5000,0],signalres3[MainSignalDrugUsing['Startsig'][a]*5000:MainSignalDrugUsing['Endsig'][a]*5000,1])\n",
    "    plt.show()\n",
    "    \n",
    "    \n",
    "    \n",
    "    print('All %s Curves Staggared:'%drugName[i])\n",
    "    count = 0\n",
    "    offset = 4000\n",
    "    for a in range(len(MainSignalDrugUsing)):\n",
    "    \n",
    "        argmin = np.argmin(signalres3[MainSignalDrugUsing['Startsig'][a]*5000:MainSignalDrugUsing['Endsig'][a]*5000,1])\n",
    "        signalres3[MainSignalDrugUsing['Startsig'][a]*5000:MainSignalDrugUsing['Endsig'][a]*5000,0] = range(0,len(signalres3[MainSignalDrugUsing['Startsig'][a]*5000:MainSignalDrugUsing['Endsig'][a]*5000,0]))\n",
    "        signalres3[MainSignalDrugUsing['Startsig'][a]*5000:MainSignalDrugUsing['Endsig'][a]*5000,0] = signalres3[MainSignalDrugUsing['Startsig'][a]*5000:MainSignalDrugUsing['Endsig'][a]*5000,0] - argmin\n",
    "    \n",
    "        plt.plot(signalres3[MainSignalDrugUsing['Startsig'][a]*5000:MainSignalDrugUsing['Endsig'][a]*5000,0],signalres3[MainSignalDrugUsing['Startsig'][a]*5000:MainSignalDrugUsing['Endsig'][a]*5000,1]-offset*(count+1))\n",
    "        count = count+1\n",
    "    plt.show()\n",
    "       \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f2e40ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.patches as mpatches\n",
    "count = 0\n",
    "for i in range(len(drugName)):\n",
    "\n",
    "    MainSignalDrugUsing = MainSignalDFTEST.loc[(MainSignalDFTEST['Drug'] == drugName[i])]\n",
    "    MainSignalDrugUsing = MainSignalDrugUsing.reset_index()\n",
    "    print('All %s Curves Staggared:'%drugName[i])\n",
    "    #count = 0\n",
    "    offset = 4000\n",
    "    drugoffset = 8000*int(i)\n",
    "    for a in range(len(MainSignalDrugUsing)):\n",
    "        \n",
    "        argmin = np.argmin(signalres3[MainSignalDrugUsing['Startsig'][a]*5000:MainSignalDrugUsing['Endsig'][a]*5000,1])\n",
    "        signalres3[MainSignalDrugUsing['Startsig'][a]*5000:MainSignalDrugUsing['Endsig'][a]*5000,0] = range(0,len(signalres3[MainSignalDrugUsing['Startsig'][a]*5000:MainSignalDrugUsing['Endsig'][a]*5000,0]))\n",
    "        signalres3[MainSignalDrugUsing['Startsig'][a]*5000:MainSignalDrugUsing['Endsig'][a]*5000,0] = signalres3[MainSignalDrugUsing['Startsig'][a]*5000:MainSignalDrugUsing['Endsig'][a]*5000,0] - argmin\n",
    "    \n",
    "        plt.plot(signalres3[MainSignalDrugUsing['Startsig'][a]*5000:MainSignalDrugUsing['Endsig'][a]*5000,0],signalres3[MainSignalDrugUsing['Startsig'][a]*5000:MainSignalDrugUsing['Endsig'][a]*5000,1]-offset*(count+1)-drugoffset,c=drugColour[i], label=drugName[i])\n",
    "        count = count+1\n",
    "        \n",
    "#plt.legend(fontsize=75)\n",
    "leg = plt.legend(drugName, labelcolor=drugColour, fontsize=100, handlelength=0, handletextpad=0)\n",
    "for item in leg.legendHandles:\n",
    "    item.set_visible(False)\n",
    "#plt.legend(handles=[mpatches.Patch(color=drugColour[0], label=drugName[0]),mpatches.Patch(color=drugColour[1], label=drugName[1]),mpatches.Patch(color=drugColour[2], label=drugName[2])], fontsize=75)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e181cac7",
   "metadata": {},
   "outputs": [],
   "source": [
    "Drug0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39335c62",
   "metadata": {},
   "source": [
    "# GOT UP TO HERE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa2cd182",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Know raw extraction start and end times (so also know length)\n",
    "\n",
    "#know percentage to halfway from start/end for human start and end\n",
    "\n",
    "#work out the true start/end from raw extraction and human percentages\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#write function that takes these start and ends, along with the whole signal to analyse these start and end points as signals"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b94a7661",
   "metadata": {},
   "source": [
    "# Quality Control"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "739b2573",
   "metadata": {},
   "outputs": [],
   "source": [
    "#make whole notebook/script runnable on eddie \n",
    "\n",
    "#will need to remove displaying graphs and increactive QC\n",
    "#can keep loading bars though\n",
    "\n",
    "#can try as both individual functions and a full pipeline\n",
    "\n",
    "#need to work out how much memory is required (cpu corse does not need to be massive, just need suitable RAM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "535af4e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "signalres3[MainSignalDF['Start Time (s)'][a]*5000:MainSignalDF['End Time (s)'][a]*5000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0654ce65",
   "metadata": {},
   "outputs": [],
   "source": [
    "globals()[iter] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f1e3008",
   "metadata": {},
   "outputs": [],
   "source": [
    "DropdownOptions = []\n",
    "for i in range(len(MainSignalDF)):\n",
    "    DropdownOptions.append(('Signal %s'%str(i+1), i))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d43b27a",
   "metadata": {},
   "source": [
    "# Run the following cell two times, and interact with it the on the second run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6923d29",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%matplotlib notebook\n",
    "from numpy import pi, sin\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.widgets import Slider, Button, RadioButtons\n",
    "\n",
    "\n",
    "SignalSelector = widgets.Dropdown(\n",
    "    options=DropdownOptions,\n",
    "    value=globals()[iter],\n",
    "    description='Signal:',\n",
    ")\n",
    "\n",
    "def reset_button_on_clicked(mouse_event):\n",
    "    start_slider.reset()\n",
    "    end_slider.reset()\n",
    "    \n",
    "def confirm_button_on_clicked(mouse_event):\n",
    "    globals()[\"StartCrop\"+str(globals()[iter])] = start_slider.val\n",
    "    globals()[\"EndCrop\"+str(globals()[iter])] = end_slider.val\n",
    "    \n",
    "    \n",
    "def sliders_on_changedstart(val):\n",
    "    ax.cla()\n",
    "    [line] = ax.plot(x, y, linewidth=0.5, color='black')\n",
    "    highlightplotstart = ax.axvline(((start_slider.val/200)*(np.max(x)-np.min(x))) + np.min(x), color='green', zorder=-1)\n",
    "    highlightplotend = ax.axvline(np.max(x) - ((end_slider.val/200)*(np.max(x)-np.min(x))), color='red', zorder=-1)\n",
    "    fig.canvas.draw_idle()\n",
    "    \n",
    "def sliders_on_changedend(val):\n",
    "    ax.cla()\n",
    "    [line] = ax.plot(x, y, linewidth=0.5, color='black')\n",
    "    highlightplotstart = ax.axvline(((start_slider.val/200)*(np.max(x)-np.min(x))) + np.min(x), color='green', zorder=-1)\n",
    "    highlightplotend = ax.axvline(np.max(x) - ((end_slider.val/200)*(np.max(x)-np.min(x))), color='red', zorder=-1)\n",
    "    fig.canvas.draw_idle()\n",
    "    \n",
    "    \n",
    "x = signalres3[MainSignalDF['Start Time (s)'][globals()[iter]]*5000:MainSignalDF['End Time (s)'][globals()[iter]]*5000,0]\n",
    "\n",
    "y = signalres3[MainSignalDF['Start Time (s)'][globals()[iter]]*5000:MainSignalDF['End Time (s)'][globals()[iter]]*5000,1]\n",
    "    \n",
    "\n",
    "\n",
    "axis_color = 'lightgoldenrodyellow'\n",
    "\n",
    "fig = plt.figure(figsize=(10,5))\n",
    "ax = fig.add_subplot(111)\n",
    "\n",
    "fig.subplots_adjust(left=0.25, bottom=0.25)\n",
    "\n",
    "[line] = ax.plot(x, y, linewidth=0.5, color='black')\n",
    "\n",
    "\n",
    "\n",
    "start_slider_ax  = fig.add_axes([0.25, 0.15, 0.65, 0.03], facecolor=axis_color)\n",
    "start_slider = Slider(start_slider_ax, 'Start', 0, 100, valinit=0)\n",
    "\n",
    "end_slider_ax = fig.add_axes([0.25, 0.1, 0.65, 0.03], facecolor=axis_color)\n",
    "end_slider = Slider(end_slider_ax, 'End', 0, 100, valinit=0)\n",
    "\n",
    "#highlightplot = ax.axvspan(start_slider.val/2, 100 - end_slider.val/2, color='green', alpha=0.5)\n",
    "highlightplotstart = ax.axvline(np.min(x), color='green', zorder=-1)\n",
    "highlightplotend = ax.axvline(np.max(x), color='red', zorder=-1)\n",
    "    \n",
    "start_slider.on_changed(sliders_on_changedstart)\n",
    "end_slider.on_changed(sliders_on_changedend)\n",
    "\n",
    "reset_button_ax = fig.add_axes([0.8, 0.025, 0.1, 0.04])\n",
    "reset_button = Button(reset_button_ax, 'Reset', color='red', hovercolor='0.975')\n",
    "\n",
    "confirm_button_ax = fig.add_axes([0.25, 0.025, 0.1, 0.04])\n",
    "confirm_button = Button(confirm_button_ax, 'Confirm', color='green', hovercolor='0.975')\n",
    "    \n",
    "reset_button.on_clicked(reset_button_on_clicked)\n",
    "confirm_button.on_clicked(confirm_button_on_clicked)\n",
    "\n",
    "    \n",
    "plt.show()\n",
    "\n",
    "def on_change(change):\n",
    "    if change['type'] == 'change' and change['name'] == 'value':\n",
    "        print(\"changed to %s\" % change['new'])\n",
    "        globals()[iter] = change['new']\n",
    "        \n",
    "        %rerun\n",
    "       \n",
    "\n",
    "SignalSelector.observe(on_change)\n",
    "\n",
    "display(SignalSelector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b92c3e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "SignalCropPercs = pd.DataFrame(columns = ['Signal', 'Start Perc', 'End Perc'])\n",
    "Signallist = []\n",
    "Startlist = []\n",
    "Endlist = []\n",
    "for i in range(len(MainSignalDF)):\n",
    "    Signallist.append('Signal %s'%str(i+1))\n",
    "    Startlist.append(globals()[\"StartCrop\"+str(i)])#SignalCropPercs['Start Perc'][i] = ['StartCrop%s'%i]\n",
    "    Endlist.append(globals()[\"EndCrop\"+str(i)])#SignalCropPercs['End Perc'][i] = ['EndCrop%s'%i]\n",
    "    \n",
    "SignalCropPercs['Signal'] = Signallist\n",
    "SignalCropPercs['Start Perc'] = Startlist\n",
    "SignalCropPercs['End Perc'] = Endlist\n",
    "\n",
    "SignalCropPercs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7f16c4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for a in range(len(MainSignalDF)):\n",
    "    print('Graph of Extracted Curve %s'%a)\n",
    "    print('Signal Length: %ss'%MainSignalDFpred['Signal Length (s)'][a])\n",
    "    print('Prediction:%s' %prediction[a])\n",
    "    plt.plot(signalres3[MainSignalDF['Start Time (s)'][a]*5000:MainSignalDF['End Time (s)'][a]*5000,1])\n",
    "    plt.show()\n",
    "    \n",
    "    def f(Signal):\n",
    "            1+1\n",
    "\n",
    "    #locals()[\"my_result\"+str(a)] = interactive(f, Signal=True)\n",
    "    locals()[\"my_result\"+str(a)] = widgets.RadioButtons(options=['Signal', 'Noise'],description='Signal or Noise:',disabled=False)\n",
    "\n",
    "    display(locals()[\"my_result\"+str(a)])\n",
    "    \n",
    "    locals()[\"UnuseableWhy\"+str(a)] = input(\"If Signal Unuseable, Why? (Leave Blank and Press Enter if Useable)\")\n",
    "    \n",
    "    \n",
    "    \n",
    "    input(\"Press Enter to Confirm\")\n",
    "    \n",
    "\n",
    "    print()\n",
    "    print()\n",
    "    clear_output()\n",
    "    \n",
    "    #change Signal Button to  radio Signal or Noise Buttons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "936ee1e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(MainSignalDF)):\n",
    "    print(locals()[\"my_result\"+str(i)].value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58007285",
   "metadata": {},
   "outputs": [],
   "source": [
    "MainSignalDF['User Entry'] = np.nan\n",
    "MainSignalDF['Unuseable Reason'] = np.nan\n",
    "\n",
    "for i in range(len(MainSignalDF)):\n",
    "    MainSignalDF['User Entry'][i] = locals()[\"my_result\"+str(i)].value\n",
    "        \n",
    "for i in range(len(MainSignalDF)):\n",
    "        MainSignalDF['Unuseable Reason'][i] = locals()[\"UnuseableWhy\"+str(i)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2b2d18c",
   "metadata": {},
   "outputs": [],
   "source": [
    "MainSignalDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0df63e9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('All Curves Overlaid:')\n",
    "for a in range(len(MainSignalDF)):\n",
    "    if MainSignalDF['User Entry'][a] == 'Noise':\n",
    "        continue\n",
    "    plt.plot(signalres3[MainSignalDF['Start Time (s)'][a]*5000:MainSignalDF['End Time (s)'][a]*5000,1])\n",
    "    \n",
    "#do another plot with overlaid and staggered all centered on global minimum of each curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea5c09ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('All Curves Overlaid:')\n",
    "for a in range(len(MainSignalDF)):\n",
    "    if MainSignalDF['User Entry'][a] == 'Noise':\n",
    "        continue\n",
    "        \n",
    "    argmin = np.argmin(signalres3[MainSignalDF['Start Time (s)'][a]*5000:MainSignalDF['End Time (s)'][a]*5000,1])\n",
    "    signalres3[MainSignalDF['Start Time (s)'][a]*5000:MainSignalDF['End Time (s)'][a]*5000,0] = range(0,len(signalres3[MainSignalDF['Start Time (s)'][a]*5000:MainSignalDF['End Time (s)'][a]*5000,0]))\n",
    "    signalres3[MainSignalDF['Start Time (s)'][a]*5000:MainSignalDF['End Time (s)'][a]*5000,0] = signalres3[MainSignalDF['Start Time (s)'][a]*5000:MainSignalDF['End Time (s)'][a]*5000,0] - argmin\n",
    "    \n",
    "    plt.plot(signalres3[MainSignalDF['Start Time (s)'][a]*5000:MainSignalDF['End Time (s)'][a]*5000,0],signalres3[MainSignalDF['Start Time (s)'][a]*5000:MainSignalDF['End Time (s)'][a]*5000,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6d7c588",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('All Curves Staggared:')\n",
    "count = 0\n",
    "offset = 4000\n",
    "for a in range(len(MainSignalDF)):\n",
    "    if MainSignalDF['User Entry'][a] == 'Noise':\n",
    "        continue\n",
    "    \n",
    "    plt.plot(signalres3[MainSignalDF['Start Time (s)'][a]*5000:MainSignalDF['End Time (s)'][a]*5000,1]-offset*(count+1))\n",
    "    count = count+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd836b48",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('All Curves Staggared:')\n",
    "count = 0\n",
    "offset = 4000\n",
    "for a in range(len(MainSignalDF)):\n",
    "    if MainSignalDF['User Entry'][a] == 'Noise':\n",
    "        continue\n",
    "    \n",
    "    argmin = np.argmin(signalres3[MainSignalDF['Start Time (s)'][a]*5000:MainSignalDF['End Time (s)'][a]*5000,1])\n",
    "    signalres3[MainSignalDF['Start Time (s)'][a]*5000:MainSignalDF['End Time (s)'][a]*5000,0] = range(0,len(signalres3[MainSignalDF['Start Time (s)'][a]*5000:MainSignalDF['End Time (s)'][a]*5000,0]))\n",
    "    signalres3[MainSignalDF['Start Time (s)'][a]*5000:MainSignalDF['End Time (s)'][a]*5000,0] = signalres3[MainSignalDF['Start Time (s)'][a]*5000:MainSignalDF['End Time (s)'][a]*5000,0] - argmin\n",
    "    \n",
    "    plt.plot(signalres3[MainSignalDF['Start Time (s)'][a]*5000:MainSignalDF['End Time (s)'][a]*5000,0],signalres3[MainSignalDF['Start Time (s)'][a]*5000:MainSignalDF['End Time (s)'][a]*5000,1]-offset*(count+1))\n",
    "    count = count+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d0f3f3c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43ca6087",
   "metadata": {},
   "outputs": [],
   "source": [
    "MainSignalDF['Predicted Type'] = prediction\n",
    "MainSignalDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b734a91b",
   "metadata": {},
   "outputs": [],
   "source": [
    "savepath = datasetusing.replace('.txt','')\n",
    "savepath"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00f66323",
   "metadata": {},
   "outputs": [],
   "source": [
    "MainSignalDF.to_excel(savepath + ' - SPREADSHEET.xlsx', index = False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "215157ac",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
