{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e13a031d",
   "metadata": {},
   "source": [
    "# Notebook for analysing data to find potential signals within\n",
    "# \n",
    "\n",
    "### How does this script work?\n",
    "First saved data in .txt form is loaded in and the dataset is extracted. The dataset is then ran through a pipeline looking for potential signals within the data and finally Dataframes are created with the characteristics of the full dataset and any signals within\n",
    "# \n",
    "### How does the pipeline work?\n",
    "The data is first analysed my a machine learning model. This model is un-supervised and is looking for regions in the data where there is high volatility, indicating a potential region of interest where a signal may be.\n",
    "\n",
    "The predictions made by the model are then looked at and any regions of interest are saved and looked into with more detail. This invloves using a cross correlation function to determine if the signal has the characteristic curve, if the extracted signal is extremely long then the cross correlation function is used to see if there is a signal within the region of interest. If the cross correlation functions show a signal is present then they are analysed looking at the length, number of peaks and height of the peaks as well as the depth of the dip. If the cross correlation function shows no signal is present then the region of interest is discarded."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8f1071d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import MLDetectionFunctionsPythonV9_5_NoRestricts_MLcreate as EEGanalysis\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import ipywidgets as widgets\n",
    "from ipywidgets import interact, interactive, Output, fixed, interact_manual\n",
    "from IPython.display import display, clear_output\n",
    "import numpy as np\n",
    "import math\n",
    "import mat73\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aefe025b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#AMAZING IDEA\n",
    "\n",
    "#What if I saved all individual areas of interest extracted by the model\n",
    "#this includes seizure events and non-seizure events\n",
    "#use this to train a model that can classify each extracted area of interest\n",
    "\n",
    "#save both raw and smoothed AoI and see which has better results\n",
    "\n",
    "\n",
    "\n",
    "#Try first - just key infor in dataframe to train with\n",
    "\n",
    "#using the extracted dataframe at the end of the code use this with either 'Signal' or 'Noise'\n",
    "#to train a model which can then be used to classify extracted AoI instead of full signals\n",
    "\n",
    "#trim down dataframe so doesnt include confusing info eg start and end times\n",
    "#intead just have signal length\n",
    "\n",
    "#include cross-corr score as well in dataframe\n",
    "#think of other things to input into the dataframe\n",
    "\n",
    "#maybe use rounded signal length (in seconds) as well as rounded dip depth, medium peak height\n",
    "\n",
    "#look at peak density throughout signal\n",
    "#rolling average over 10secs and pick median, mean or peak value?\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#this looks to be a very good idea"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1566f48",
   "metadata": {},
   "source": [
    "# Importing data to analyse\n",
    "\n",
    "### Each dataset should be saved as a .txt file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3608c6d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "realdatafile1 = 'Long_Data_1.txt'\n",
    "realdatafile2 = 'Long_Data_2.txt'\n",
    "realdatafile3 = 'Long_Data_3.txt'\n",
    "realdatafile4 = 'Long_Data_4.txt'\n",
    "\n",
    "realdatafile5 = 'Short_Data_1.txt'\n",
    "\n",
    "realdatafile6 = '22.07.22_Example_Data_Long.txt'\n",
    "realdatafile7 = '22.07.22_Example_Data_Long2.txt'\n",
    "\n",
    "realdatafile8 = '041022_Example_Data_Long_NoisyMW117CH1.txt'\n",
    "realdatafile9 = '041022_Example_Data_Long_SpikesMW117CH3.txt'\n",
    "\n",
    "realdatafile10 = '12.10.22_Example_Data_Long_Spikes-Venus16.3CH1.txt' #this is same as a previous file\n",
    "\n",
    "realdatafile11 = '041022ExampleDataLongVenus13p1CH1.txt' #could be all noise as 'signals' all very short\n",
    "realdatafile12 = '041022ExampleDataLongVenus13p1CH2.txt' #also very difficult to classify as nearly all could be signal or noise\n",
    "realdatafile13 = '041122ExampleDataLongVenus7p3CH3.txt'\n",
    "realdatafile14 = '041122ExampleDataLongVenus7p3CH4.txt'\n",
    "realdatafile15 = '041122ExampleDataLongVenus10p1CH1.txt'\n",
    "realdatafile16 = '041122ExampleDataLongVenus10p1CH2.txt'\n",
    "realdatafile17 = '041122ExampleDataLongVenus12p3CH1.txt'\n",
    "realdatafile18 = '041122ExampleDataLongVenus12p3CH2.txt'\n",
    "realdatafile19 = '041122ExampleDataLongVenus13p3CH1.txt' #no extractions\n",
    "realdatafile20 = '041122ExampleDataLongVenus13p3CH2.txt' #no extractions\n",
    "\n",
    "#start of novel analysis\n",
    "realdatafile21 = '21.11.23 - MW3 - CH2.txt'\n",
    "realdatafile22 = '21.12.02 - MW30 - CH3.txt'\n",
    "realdatafile23 = '22.01.24 - MW63 - CH2.txt' #unique error\n",
    "realdatafile24 = '22.01.24 - MW65 - CH1.txt'\n",
    "realdatafile25 = '22.01.21 - MW61 - CH2.txt'\n",
    "realdatafile26 = '21.12.14 - MW51 - CH2.txt'\n",
    "realdatafile27 = '21.12.15 - MW58 - CH3.txt' #lots of very smooth signals, well detected and classified\n",
    "\n",
    "\n",
    "noveldata1 = '/mnt/datafast/Douglas/MaxTransfer/NewDataToAnalyse/21.11.23 - MW3 - CH2.txt' #some signals, extractions possibly too long\n",
    "noveldata2 = '/mnt/datafast/Douglas/MaxTransfer/NewDataToAnalyse/21.11.23 - MW5 - CH2.txt' #unique error FIXED. 2 extractions, both seem to be calibration noise classified as signal\n",
    "noveldata3 = '/mnt/datafast/Douglas/MaxTransfer/NewDataToAnalyse/21.11.25 - MW7 - CH1.txt' #single extraction, noise\n",
    "noveldata4 = '/mnt/datafast/Douglas/MaxTransfer/NewDataToAnalyse/21.11.25 - MW9 - CH2.txt' #same unique error FIXED. about 10 extractions, all noise except a few calibrations classified as signal\n",
    "noveldata5 = '/mnt/datafast/Douglas/MaxTransfer/NewDataToAnalyse/21.11.29 - MW13 - CH3.txt' #one extraction, noise\n",
    "noveldata6 = '/mnt/datafast/Douglas/MaxTransfer/NewDataToAnalyse/21.11.30 - MW19 - CH2.txt' #3 extracts, all noise\n",
    "noveldata7 = '/mnt/datafast/Douglas/MaxTransfer/NewDataToAnalyse/21.11.30 - MW19 - CH4.txt' #no extracts\n",
    "noveldata8 = '/mnt/datafast/Douglas/MaxTransfer/NewDataToAnalyse/21.12.02 - MW21 - CH4.txt' #3 extracts, all noise\n",
    "noveldata9 = '/mnt/datafast/Douglas/MaxTransfer/NewDataToAnalyse/21.12.02 - MW25 - CH1.txt' #4 signals extracted, last one possible starting too early\n",
    "noveldata10 = '/mnt/datafast/Douglas/MaxTransfer/NewDataToAnalyse/21.12.02 - MW29 - CH1.txt' #4 extracts, 1/2 disputable signals\n",
    "noveldata11 = '/mnt/datafast/Douglas/MaxTransfer/NewDataToAnalyse/21.12.02 - MW29 - CH2.txt' #4 extracts, all noise\n",
    "noveldata12 = '/mnt/datafast/Douglas/MaxTransfer/NewDataToAnalyse/21.12.02 - MW30 - CH3.txt' #1 extract, noise\n",
    "noveldata13 = '/mnt/datafast/Douglas/MaxTransfer/NewDataToAnalyse/21.12.02 - MW32 - CH4.txt' #no extractions\n",
    "noveldata14 = '/mnt/datafast/Douglas/MaxTransfer/NewDataToAnalyse/21.12.06 - MW33 - CH2.txt' #4 extracts. all noise but 1 wrongly classified as signal\n",
    "noveldata15 = '/mnt/datafast/Douglas/MaxTransfer/NewDataToAnalyse/21.12.06 - MW35 - CH1.txt' #4 extracts, all noise\n",
    "noveldata16 = '/mnt/datafast/Douglas/MaxTransfer/NewDataToAnalyse/21.12.06 - MW36 - CH4.txt' #1 extract, noise\n",
    "noveldata17 = '/mnt/datafast/Douglas/MaxTransfer/NewDataToAnalyse/21.12.08 - MW41 - CH1.txt' #v strong signals. 4 extracts, 3 clear signals, 1 possible noise/signal\n",
    "noveldata18 = '/mnt/datafast/Douglas/MaxTransfer/NewDataToAnalyse/21.12.08 - MW42 - CH3.txt' #again, some good signals. 7 extractions, some signal and noise. all well classified\n",
    "noveldata19 = '/mnt/datafast/Douglas/MaxTransfer/NewDataToAnalyse/21.12.09 - MW46 - CH4.txt' #dubios signal extractions. look to be a rig calibration\n",
    "noveldata20 = '/mnt/datafast/Douglas/MaxTransfer/NewDataToAnalyse/21.12.14 - MW51 - CH2.txt' #8 extracts, mainly noise with 1 possible signal\n",
    "noveldata21 = '/mnt/datafast/Douglas/MaxTransfer/NewDataToAnalyse/21.12.14 - MW53 - CH1.txt'#mega dataset size. lots of extractions 30+, many signals and noise\n",
    "noveldata22 = '/mnt/datafast/Douglas/MaxTransfer/NewDataToAnalyse/21.12.14 - MW54 - CH3.txt'#mega dataset size, 40+ extractions. lots of signals and noise\n",
    "noveldata23 = '/mnt/datafast/Douglas/MaxTransfer/NewDataToAnalyse/21.12.15 - MW58 - CH3.txt'#nice example dataset. lots of very well extracted signals\n",
    "noveldata24 = '/mnt/datafast/Douglas/MaxTransfer/NewDataToAnalyse/21.12.15 - MW58 - CH4.txt'#struggles with correct detection (could make for good training data). lots of single dips classified as signal\n",
    "noveldata25 = '/mnt/datafast/Douglas/MaxTransfer/NewDataToAnalyse/22.01.21 - MW61 - CH2.txt'#lots of extractions, many noise and some signals. signals are of interesting shape\n",
    "noveldata26 = '/mnt/datafast/Douglas/MaxTransfer/NewDataToAnalyse/22.01.24 - MW63 - CH1.txt'#generally good extraction, maybe cuts some signals short\n",
    "noveldata27 = '/mnt/datafast/Douglas/MaxTransfer/NewDataToAnalyse/22.01.24 - MW63 - CH2.txt'#a few nice signals but also some noise (possibly some misclassified noise)\n",
    "noveldata28 = '/mnt/datafast/Douglas/MaxTransfer/NewDataToAnalyse/22.01.24 - MW64 - CH3.txt' # lots of signals and noise, some possibly misclassified\n",
    "noveldata29 = '/mnt/datafast/Douglas/MaxTransfer/NewDataToAnalyse/22.01.24 - MW65 - CH1.txt'#only 2 extractions, both nosie\n",
    "noveldata30 = '/mnt/datafast/Douglas/MaxTransfer/NewDataToAnalyse/22.01.24 - MW65 - CH2.txt' #7 extractions, all noise but 2 possible signals\n",
    "#re-run all novel data as MainDataframe wasnt sorted correctly and could have incorrect predictions for the signal number\n",
    "#signals that were X.1 X.2 might not be sorted correctly\n",
    "\n",
    "\n",
    "realdatafile21van = '2022_09_30_socialtaskephys_exp_SGHRB_subject2777_Int16ch5K0_I2C625Hz_1ADC200K_IR320K.edf'\n",
    "realdatafile22van = '2022_09_30_socialtaskephys_exp_SGHRB_subject2777_Int16ch5K0_I2C625Hz_1ADC200K_IR320K.mat'\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "curvedata = 'SpikeWaveDischarge.txt'\n",
    "\n",
    "#add start and end vals to compare with Max spreadsheet into dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e7a9dad",
   "metadata": {},
   "source": [
    "# Choosing which dataset to analyse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94f24dc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "datasetusing = noveldata28\n",
    "\n",
    "#check 5, boarderline on signal/noise (especially 3rd signal)\n",
    "\n",
    "#8 is good for testing with 'clean' dataset that works v well with original 9_5 version\n",
    "\n",
    "#11 has detection issues\n",
    "#14 is cool as works well\n",
    "#15 cool too\n",
    "#16 is v good\n",
    "#17 detection issues due to dip depth too small and thus removing signal\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1904ae0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "realdatausing = EEGanalysis.getdata(datasetusing)\n",
    "realdatausing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be5cac38",
   "metadata": {},
   "outputs": [],
   "source": [
    "DFnorm, signal = EEGanalysis.CreateDataframe(realdatausing)\n",
    "DFnormres, signalres2 = EEGanalysis.CreateDataframe(realdatausing)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4c6ad15",
   "metadata": {},
   "source": [
    "# Formatting the curve data to use in cross correlation to determine validity of potential signals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5de3c334",
   "metadata": {},
   "outputs": [],
   "source": [
    "curvedata = EEGanalysis.getdata(curvedata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f915ff3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "timecurve, signalcurve = EEGanalysis.timesignal(curvedata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f10b5dcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "signalcurveave = EEGanalysis.movingaverage(signalcurve[:,1],10000)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9182773b",
   "metadata": {},
   "source": [
    "# Predicting the locations of potential signals within the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "420c18eb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "StartVals, EndVals, signalCURVES = EEGanalysis.PredictSignal(DFnorm, signal,350000)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbef81a3",
   "metadata": {},
   "source": [
    "# Analysing the whole dataset before and potential signals have been removed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "657681cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "MainSignalDFtestfull = EEGanalysis.AnalyseSignalFullData(signal)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "766c89fe",
   "metadata": {},
   "source": [
    "# Extracting potential individual signals, determining their validity and analysing them where necessary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e8f05d3",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "MainSignalDF, MainSignalDFraw, MainSignalDFccextracts,redsig = EEGanalysis.AnalyseSignalsFailsafeVer(StartVals,EndVals,signal,signalres2,signalCURVES,DFnorm,signalcurveave,250000)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65bebefa",
   "metadata": {},
   "source": [
    "# Analysing the remaining data after valid signals have been removed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "828e884a",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "MainSignalDFtestfullthird = EEGanalysis.AnalyseSignalFullData(redsig)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "150c22d0",
   "metadata": {},
   "source": [
    "# Dataframe containing characteristics of full original data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0af31777",
   "metadata": {},
   "outputs": [],
   "source": [
    "MainSignalDFtestfull"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "192d4605",
   "metadata": {},
   "source": [
    "# Dataframe containing characteristics of initially extracted signals, not including any second tier extractions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01814f29",
   "metadata": {},
   "outputs": [],
   "source": [
    "MainSignalDFraw"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3e9cd95",
   "metadata": {},
   "source": [
    "# Dataframe containing characteristics of only second tier extractions\n",
    "\n",
    "### This is where a signal was within an initial extraction but the original signal contained more data then just the signal\n",
    "\n",
    "### The signal is extracted using cross correlation to trim out the 'excess' data from the original extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6872009e",
   "metadata": {},
   "outputs": [],
   "source": [
    "MainSignalDFccextracts"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8571ddb",
   "metadata": {},
   "source": [
    "# Dataframe containing the characteristics of the full data with signals removed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4edfcc0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "MainSignalDFtestfullthird"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9ae3a6d",
   "metadata": {},
   "source": [
    "# Combining the dataframes containing original extracted signals and second tier extractions\n",
    "\n",
    "### Original extractions are labelled with .0 i.e. 5.0 or 8.0\n",
    "\n",
    "### Second tier extractions are labelled with .1 .2 .3 depending on how many second tier extractions there are within one original signal  i.e original signal 6 may have two signals within it and they would be labelled 6.1 and 6.2   original signal 9 may have one signal within it and would be labelled 9.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0c4b6a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "MainSignalDFtot = MainSignalDFraw.append(MainSignalDFccextracts, ignore_index=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4de7c2e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "MainSignalDFtot['SignalNumber'] = MainSignalDFtot['SignalNumber'].str.split('Signal').str.join('')\n",
    "\n",
    "MainSignalDFtot['SignalNumber'] = pd.to_numeric(MainSignalDFtot['SignalNumber'])\n",
    "\n",
    "MainSignalDFtot=MainSignalDFtot.sort_values('SignalNumber')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d02c49e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "MainSignalDF = MainSignalDF.rename(columns={\"Startsig\": \"Start Time (s)\", \"Endsig\": \"End Time (s)\"\n",
    "                                           , \"SignalLength\": \"Signal Length (s)\"\n",
    "                                           , \"NoPeaksBeforeGlobal\": \"Peaks Before Global Min\"\n",
    "                                           , \"NoPeaksAfterGlobal\": \"Peaks After Global Min\"\n",
    "                                           , \"NoDipsBeforeGlobal\": \"Dips Before Global Min\"\n",
    "                                           , \"NoDipsAfterGlobal\": \"Dips After Global Min\"\n",
    "                                           , \"DipDepth\": \"Global Min Depth\"\n",
    "                                           , \"Start\": \"Start Index\"\n",
    "                                           , \"End\": \"End Index\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c22c572",
   "metadata": {},
   "outputs": [],
   "source": [
    "MainSignalDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4407b218",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f90ca91c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#MainSignalDF['SignalNumber'] = [1,2,3,4,5]\n",
    "#MainSignalDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "145bad03",
   "metadata": {},
   "outputs": [],
   "source": [
    "#MainSignalDF.to_csv('Dataset7Output.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "077990dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "realdataV2 = EEGanalysis.getdata(datasetusing)\n",
    "DFnorm3, signalres3 = EEGanalysis.CreateDataframe(realdataV2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5edf5671",
   "metadata": {},
   "outputs": [],
   "source": [
    "MainSignalDF = MainSignalDF.fillna(0)\n",
    "MainSignalDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef35df9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "MainSignalDF = MainSignalDF.sort_index()\n",
    "MainSignalDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d40202d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#MainSignalDF = MainSignalDF.drop([1])\n",
    "#MainSignalDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96eadc86",
   "metadata": {},
   "outputs": [],
   "source": [
    "MainSignalDFpred = MainSignalDF.sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0914268e",
   "metadata": {},
   "outputs": [],
   "source": [
    "MainSignalDFpred = MainSignalDFpred.astype(float).round(0).astype(int)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fbbcf52",
   "metadata": {},
   "outputs": [],
   "source": [
    "MainSignalDFpred = MainSignalDFpred.drop('Start Time (s)', axis=1)\n",
    "MainSignalDFpred = MainSignalDFpred.drop('End Time (s)', axis=1)\n",
    "MainSignalDFpred = MainSignalDFpred.drop('Start Index', axis=1)\n",
    "MainSignalDFpred = MainSignalDFpred.drop('End Index', axis=1)\n",
    "MainSignalDFpred = MainSignalDFpred.drop('SignalNumber', axis=1)\n",
    "MainSignalDFpred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6025bc04",
   "metadata": {},
   "outputs": [],
   "source": [
    "MLclassifier = pickle.load(open('PotentialSignalClassifier.sav', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80caca0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "MainSignalDFpredar = MainSignalDFpred.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42669d8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction = MLclassifier.predict(MainSignalDFpredar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53db5630",
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e110649",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49ea02aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('All Curves Overlaid:')\n",
    "for a in range(len(MainSignalDF)):\n",
    "    plt.plot(signalres3[MainSignalDF['Start Time (s)'][a]*5000:MainSignalDF['End Time (s)'][a]*5000,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb734838",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('All Curves Staggared:')\n",
    "for a in range(len(MainSignalDF)):\n",
    "    plt.plot(signalres3[MainSignalDF['Start Time (s)'][a]*5000:MainSignalDF['End Time (s)'][a]*5000,1]-2000*(a+1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c934289",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for a in range(len(MainSignalDF)):\n",
    "    print('Graph of Extracted Curve %s'%a)\n",
    "    print('Signal Length: %ss'%MainSignalDFpred['Signal Length (s)'][a])\n",
    "    print(prediction[a])\n",
    "    plt.plot(signalres3[MainSignalDF['Start Time (s)'][a]*5000:MainSignalDF['End Time (s)'][a]*5000,1])\n",
    "    plt.show()\n",
    "    print()\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7f16c4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for a in range(len(MainSignalDF)):\n",
    "    print('Graph of Extracted Curve %s'%a)\n",
    "    print('Signal Length: %ss'%MainSignalDFpred['Signal Length (s)'][a])\n",
    "    print('Prediction:%s' %prediction[a])\n",
    "    plt.plot(signalres3[MainSignalDF['Start Time (s)'][a]*5000:MainSignalDF['End Time (s)'][a]*5000,1])\n",
    "    plt.show()\n",
    "    \n",
    "    def f(Signal):\n",
    "            1+1\n",
    "\n",
    "    locals()[\"my_result\"+str(a)] = interactive(f, Signal=True)\n",
    "\n",
    "    display(locals()[\"my_result\"+str(a)])\n",
    "    \n",
    "    locals()[\"UnuseableWhy\"+str(a)] = input(\"If Signal Unuseable, Why? (Leave Blank and Press Enter if Useable)\")\n",
    "    \n",
    "    \n",
    "    \n",
    "    input(\"Press Enter to Confirm\")\n",
    "    \n",
    "\n",
    "    print()\n",
    "    print()\n",
    "    clear_output()\n",
    "    \n",
    "    #change Signal Button to  radio Signal or Noise Buttons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58007285",
   "metadata": {},
   "outputs": [],
   "source": [
    "MainSignalDF['User Entry'] = np.nan\n",
    "MainSignalDF['Unuseable Reason'] = np.nan\n",
    "\n",
    "for i in range(len(MainSignalDF)):\n",
    "    if locals()[\"my_result\"+str(i)].children[0].value == True:\n",
    "        MainSignalDF['User Entry'][i] = 'Signal'\n",
    "    else:\n",
    "        MainSignalDF['User Entry'][i] = 'Noise'\n",
    "        \n",
    "for i in range(len(MainSignalDF)):\n",
    "        MainSignalDF['Unuseable Reason'][i] = locals()[\"UnuseableWhy\"+str(i)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2b2d18c",
   "metadata": {},
   "outputs": [],
   "source": [
    "MainSignalDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43ca6087",
   "metadata": {},
   "outputs": [],
   "source": [
    "MainSignalDF['Predicted Type'] = prediction\n",
    "MainSignalDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b734a91b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#savepath = datasetusing.replace('.txt','')\n",
    "#savepath"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00f66323",
   "metadata": {},
   "outputs": [],
   "source": [
    "#MainSignalDF.to_excel(savepath + ' - SPREADSHEET.xlsx', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "215157ac",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
